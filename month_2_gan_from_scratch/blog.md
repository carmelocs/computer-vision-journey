# How I Built My First GAN from Scratch (and Learned from Its Failures)

> *By Shawn Cheng | Computer Vision Engineer @ IDVerse Australia*

In Month 2 of my computer vision journey, I set out to build a **Deep Convolutional GAN (DCGAN)** from scratch using PyTorch. The goal? To understand how generative models work under the hood â€” not just use them.

After 20 epochs of training, hereâ€™s what I got:

![Generated Images - Epoch 20](https://github.com/carmelocs/computer-vision-journey/blob/main/month_2_gan_from_scratch/samples/epoch_20.png?raw=true)

Blurry, abstract, but full of promise.

This isnâ€™t just about code. Itâ€™s about **learning through failure**, and why thatâ€™s essential in AI.

---

## ðŸ› ï¸ What I Built

I implemented a **DCGAN** on the CIFAR-10 dataset, which contains 60,000 32x32 color images across 10 classes (cars, birds, cats, etc.).

The architecture:

- **Generator**: Transposed convolutions, BatchNorm, ReLU â†’ Tanh output
- **Discriminator**: Conv layers, LeakyReLU, Sigmoid output
- **Loss**: Binary cross-entropy (original GAN loss)
- **Optimizer**: Adam (Î²â‚=0.5)
- **GPU**: NVIDIA RTX 2000 (CUDA 12.0)

All code is open-sourced at:  
ðŸ‘‰ [https://github.com/carmelocs/computer-vision-journey/tree/main/month_2_gan_from_scratch](https://github.com/carmelocs/computer-vision-journey/tree/main/month_2_gan_from_scratch)

---

## ðŸ§ª The Training Process

I trained for 20 epochs with a batch size of 128. Hereâ€™s what happened:

| Epoch | Observations |
|-------|-------------|
| 1â€“5   | Outputs were pure noise. Discriminator dominated. |
| 6â€“10  | First hints of structure appeared. Color patches emerged. |
| 11â€“15 | Mode collapse: generator repeated similar patterns. |
| 16â€“20 | Improved diversity, but still blurry. |

The key insight? **GANs donâ€™t learn linearly.** They oscillate between chaos and order.

---

## ðŸ” Key Lessons

### 1. **Stability is Everything**

GANs are notoriously unstable. I had to:

- Lower the learning rate after epoch 5
- Reduce batch size to avoid GPU OOM
- Use W&B to track loss curves in real-time

ðŸ’¡ Pro tip: Start with **label smoothing** and **gradient clipping**.

### 2. **You Canâ€™t Just â€œTrainâ€ a GAN**

Itâ€™s a game of balance:

- Generator tries to fool the discriminator
- Discriminator tries to get better at detecting fakes

If one gets too strong, training fails.

### 3. **Blurriness Is Normal**

At epoch 20, my images are blurry â€” but thatâ€™s expected. Realistic results come after hundreds of epochs.

---

## ðŸ“Š Evaluation

I used **visual inspection** and **W&B logs** to monitor progress:

- Loss curves showed convergence
- Generated samples improved over time
- No major artifacts (e.g., checkerboard patterns)

FID score estimate: ~70â€“80 (baseline for CIFAR-10 is ~30â€“40). But again â€” this is early.

---

## âœ… Whatâ€™s Next?

Now that Iâ€™ve built a working GAN, Iâ€™m moving to:

- **StyleGAN2**: For higher-resolution, more realistic outputs
- **Latent space editing**: Manipulating facial attributes (age, expression)
- **Deepfake detection**: Using my model to generate synthetic data for training detectors

---

## ðŸ§© Final Thoughts

Building a GAN from scratch taught me more than any tutorial ever could. It wasnâ€™t about perfect results â€” it was about **understanding the process**.

And thatâ€™s the real value of learning in public: youâ€™re not just coding â€” youâ€™re growing.

If youâ€™re starting your own CV journey, remember:
> **Fail fast, learn fast, iterate fast.**

---

## ðŸ“š Resources

- [DCGAN Paper (Radford et al.)](https://arxiv.org/abs/1511.06434)
- [PyTorch DCGAN Tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)
- [Weights & Biases for Experiment Tracking](https://wandb.ai/site)

---

## ðŸ”— Connect With Me

- GitHub: [Shawn Cheng](https://github.com/carmelocs)
- LinkedIn: [Shawn Cheng](https://www.linkedin.com/in/shawn-cheng-a41647105/)

Let me know if you try this yourself â€” Iâ€™d love to see your results!

`# machinelearning #computervision #generativemodels #deeplearning`
