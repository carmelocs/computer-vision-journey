# How I Built My First GAN from Scratch (and Learned from Its Failures)

> *By Shawn Cheng | Computer Vision Engineer @ IDVerse Australia*

In Month 2 of my computer vision journey, I set out to build a **Deep Convolutional GAN (DCGAN)** from scratch using PyTorch. Not with a pre-trained model. Not by copying code blindly. But **from first principles** â€” layers, losses, and all.

The goal? To truly understand how generative models work under the hood. Because at IDVerse, where I work on deepfake generation for training data, knowing *how* things break is just as important as knowing how they work.

After 20 epochs of training on CIFAR-10, hereâ€™s what I got:

![Generated Images - Epoch 20](./samples/epoch_20.png)  
*64 synthetic images generated after 20 epochs. Still blurry â€” but showing signs of structure.*

Theyâ€™re not photorealistic. They donâ€™t look like birds or cars yet. But theyâ€™re not noise either.

And that, in itself, is a win.

This isnâ€™t just about code. Itâ€™s about **learning through failure**, debugging in real time, and building intuition â€” one epoch at a time.

---

## ðŸ› ï¸ What I Built

I implemented a **DCGAN** based on the [original paper by Radford et al. (2015)](https://arxiv.org/abs/1511.06434), trained on the **CIFAR-10 dataset** (60k 32x32 color images across 10 classes).

### Architecture Overview

- **Generator**:  
  Input: 100-dim latent vector â†’ Transposed convolutions + BatchNorm â†’ Output: 3x64x64 image (Tanh)
- **Discriminator**:  
  Input: Image â†’ Strided convolutions + LeakyReLU â†’ Output: Real/Fake probability (Sigmoid)
- **Loss**: Binary cross-entropy (BCE)
- **Optimizer**: Adam (`lr=0.0002`, `Î²â‚=0.5`)
- **Batch size**: 128
- **Hardware**: NVIDIA RTX 2000 (CUDA 12.0)

All code is open-sourced in my learning repo:  
ðŸ‘‰ [github.com/carmelocs/computer-vision-journey](https://github.com/carmelocs/computer-vision-journey)

---

## ðŸ§ª The Training Process

Training a GAN is less like driving a car and more like balancing two wrestlers.

Hereâ€™s how it unfolded:

| Epoch | Observations |
|-------|-------------|
| 1â€“5   | Pure noise. Discriminator dominated. Generator made no progress. |
| 6â€“10  | First hints of structure. Color blobs emerged. Mode collapse started. |
| 11â€“15 | Repeated patterns â€” generator â€œcheatedâ€ by producing similar outputs. |
| 16â€“20 | Slight improvement in diversity. Still blurry, but coherent. |

The key insight? **GANs donâ€™t learn smoothly**. They oscillate between chaos and order â€” and your job is to keep them dancing.

---

## ðŸ” Key Lessons from the Trenches

### 1. **Stability Is Everything**

GANs are notoriously unstable. I had to:

- Lower the learning rate after epoch 5
- Reduce batch size from 256 â†’ 128 to avoid CUDA OOM
- Use **Weights & Biases (W&B)** to track loss curves in real time

ðŸ’¡ Pro tip: Start with **label smoothing** and **gradient penalty** in future projects.

### 2. **You Canâ€™t Just â€œTrainâ€ a GAN**

Itâ€™s a game of balance:

- If the **discriminator gets too strong**, the generator gets vanishing gradients.
- If the **generator wins early**, mode collapse sets in.

I found success by alternating updates 1:1 and monitoring both losses carefully.

### 3. **Blurriness Is Normal**

At epoch 20, expecting sharp images is unrealistic. Realistic results take hundreds of epochs â€” especially without tricks like spectral normalization or progressive growing.

But blurriness â‰  failure. It means learning is happening.

---

## ðŸ“Š Evaluation: Beyond Visual Inspection

I used:

- **W&B logs** to monitor `loss_gen` and `loss_disc`
- **Visual inspection** of generated samples every 5 epochs
- **FID estimate**: ~75 (baseline for good GANs on CIFAR-10 is ~30â€“40)

While performance isnâ€™t stellar yet, the trajectory is positive â€” and thatâ€™s what matters.

---

## âœ… Whatâ€™s Next?

Now that Iâ€™ve built a working DCGAN, Iâ€™m moving to:

- **StyleGAN2-ADA**: For higher-resolution, more realistic face generation
- **Latent space editing**: Manipulating attributes like age, expression, lighting
- **Deepfake detection**: Using synthetic data from my own models to train robust detectors

Because at IDVerse, we donâ€™t just generate fakes â€” we also need to detect them.

---

## ðŸ§© Final Thoughts

Building a GAN from scratch taught me more than any tutorial ever could. It wasnâ€™t about perfect results â€” it was about understanding the **dance between generator and discriminator**, the **importance of hyperparameters**, and the **value of patience**.

And thatâ€™s the real value of learning in public:  
Youâ€™re not just coding â€” youâ€™re growing.

If youâ€™re starting your own CV journey, remember:
> **Fail fast. Learn faster. Iterate constantly.**

Because mastery isnâ€™t about getting it right the first time.  
Itâ€™s about getting it right *eventually* â€” and knowing how you got there.

---

## ðŸ“š Resources

- [DCGAN Paper (Radford et al., 2015)](https://arxiv.org/abs/1511.06434)
- [PyTorch DCGAN Tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)
- [Weights & Biases (W&B)](https://wandb.ai/site)
- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)

---

## ðŸ”— Connect With Me

- GitHub: [Shawn Cheng](https://github.com/carmelocs)
- LinkedIn: [Shawn Cheng](https://www.linkedin.com/in/shawn-cheng-a41647105/)

Let me know if you try this yourself â€” Iâ€™d love to see your generated images!

`# machinelearning #computervision #generativemodels #deeplearning`
