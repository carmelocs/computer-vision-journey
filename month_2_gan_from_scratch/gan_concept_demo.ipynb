{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652def94",
   "metadata": {},
   "source": [
    "# GAN Concept Demo: Building Blocks of Deepfake Generators\n",
    "\n",
    "This notebook demonstrates the core components of a Generative Adversarial Network (GAN).  \n",
    "We define a simple Generator and Discriminator using PyTorch, show the training loop logic, and visualize how adversarial learning works â€” even if we don't fully train it here.\n",
    "\n",
    "> ðŸ’¡ This prepares us for building a real DCGAN in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from models.generator import Generator\n",
    "from models.discriminator import Discriminator\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91176ef7",
   "metadata": {},
   "source": [
    "## 1. Define the Generator\n",
    "\n",
    "The Generator learns to map from a random noise vector (z) to a synthetic image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9646aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "generator = Generator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db915bd0",
   "metadata": {},
   "source": [
    "## 2. Define the Discriminator\n",
    "\n",
    "The Discriminator classifies images as real (1) or fake (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1baf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f306062",
   "metadata": {},
   "source": [
    "## 3. Loss Function & Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross-Entropy Loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "lr = 0.0002\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05ab281",
   "metadata": {},
   "source": [
    "## 4. Simulate One Training Step\n",
    "\n",
    "We simulate one batch of real/fake images and show how gradients flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data: batch of 4, 32x32 RGB images\n",
    "real_images = torch.randn(4, 3, 32, 32).to(device)\n",
    "print(\"Real image shape:\", real_images.shape)\n",
    "batch_size = real_images.size(0)\n",
    "\n",
    "# Labels\n",
    "real_labels = torch.ones(batch_size, 1).to(device)\n",
    "fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# Train Discriminator\n",
    "# ----------------------------\n",
    "d_optimizer.zero_grad()\n",
    "\n",
    "# Real images\n",
    "pred_real = discriminator(real_images)\n",
    "loss_real = criterion(pred_real, real_labels)\n",
    "\n",
    "# Fake images\n",
    "noise = torch.randn(batch_size, 100).to(device)\n",
    "print(\"Noise shape:\", noise.shape)\n",
    "fake_images = generator(noise)\n",
    "print(\"Fake image shape:\", fake_images.shape)\n",
    "pred_fake = discriminator(fake_images.detach())  # Detach to stop gradient to G, gradients stop at fake_images â€” they donâ€™t flow back to the G.\n",
    "print(\"Disc output shape:\", pred_fake.shape)\n",
    "loss_fake = criterion(pred_fake, fake_labels)\n",
    "\n",
    "# Total loss\n",
    "d_loss = loss_real + loss_fake\n",
    "d_loss.backward()\n",
    "d_optimizer.step()\n",
    "\n",
    "# ----------------------------\n",
    "# Train Generator\n",
    "# ----------------------------\n",
    "g_optimizer.zero_grad()\n",
    "pred_fake_for_g = discriminator(fake_images)  # Re-run through D\n",
    "g_loss = criterion(pred_fake_for_g, real_labels)  # Fool D into thinking fake is real\n",
    "g_loss.backward()\n",
    "g_optimizer.step()\n",
    "\n",
    "print(f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ef4bcf",
   "metadata": {},
   "source": [
    "## 5. Visualize Generated \"Fake\" Images (Random Noise â†’ Image)\n",
    "\n",
    "Even untrained, the generator outputs structured tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a319d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 4 fake images\n",
    "with torch.no_grad():\n",
    "    noise_sample = torch.randn(4, 100).to(device)\n",
    "    generated_images = generator(noise_sample)\n",
    "\n",
    "# # Denormalize from [-1, 1] to [0, 1]\n",
    "# generated_images = (generated_images.cpu() + 1) / 2\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "for i in range(4):\n",
    "    img = generated_images[i].permute(1, 2, 0).cpu().numpy()\n",
    "    # axes[i].imshow(np.clip(img, 0, 1))\n",
    "    # img = np.transpose(generated_images[i].cpu().numpy(), (1, 2, 0))\n",
    "    img = (img - img.min()) / (img.max() - img.min())  # Normalize per image\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis(\"off\")\n",
    "    axes[i].set_title(f\"Fake Image {i+1}\")\n",
    "\n",
    "plt.suptitle(\"Untrained Generator Outputs\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5fd041",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 6. Model Summary\n",
    "\n",
    "Use `torchinfo` to show layer shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372be342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torchinfo  # install torchinfo if not done yet\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(generator, input_size=(1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd52833",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(discriminator, input_size=(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c1ffa",
   "metadata": {},
   "source": [
    "## âœ… Key Takeaways\n",
    "\n",
    "- The **Generator** maps noise â†’ image.\n",
    "- The **Discriminator** learns to distinguish real vs. fake.\n",
    "- They are trained in **adversarial alternation**.\n",
    "- Even without full training, the architecture shows how deepfakes are created.\n",
    "\n",
    "> ðŸ”œ Next: We'll train a real DCGAN on cifar10 / CelebA dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-journey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
